#git more practice!!!!!
#git practice!!!!!!!!!!
#PART 1:
import os
import pandas as pd
import sys #sys.exit()
import glob
#PART 2:
from netCDF4 import Dataset
import numpy as np
from matplotlib import pyplot as plt
# ~~~~~~~   function  ~~~~~~~~~~~~

def pixel_pull():
    pass

def pixel_plot():
    pass





# ~~~~~~~   loop thru rescaled lidar flights  ~~~~~~~~~~~~
# PART I:
path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/all_rescaled/'
dates = [] #allocate dates list
# dt_str = [] #allocate dates list

# for files in os.walk(path): #go through every directory in path
for root, dirs, files in os.walk(path): #go through every directory in path
    for f in files:
        if f.split(".")[-1]=="tif": #only grabs .tifs (excludes my readme file)
            # date_parse = f.split("_")[-1] #split at '_' and save second result (-1 = end)
            dt_str = "".join([c for c in f if c.isnumeric()]) #list comprehension: same as below
                    # for c in date_parse:
                    #     if c.is_numric()
                                #...join....? "" how you want to join them. ex. ","
            dates.append(dt_str) #adds date to []

dates = pd.to_datetime(dates) #convert date strings to datetime type
# print(len(dates)) #final list, outside of for loops
# print(f,dt_str,dates)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#PART II:

# sys.exit() #don't run anything below

# # ~~~~~~~   set site locations  ~~~~~~~~~~~~
# path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/all_rescaled/nc_lidar'

path = '/home/meganmason/Documents/projects/thesis/data/processing_lidar/depths_3m/all_rescaled/nc_lidar/rescaled_20130403.nc'

filename = path
## 1. Read the file and index x and y
ds = Dataset(filename)
# print(ds.variables.keys()) #see key names: 'x','y','Band1'
lat = ds.variables['x']
lon = ds.variables['y']

# grab lat/lon values (in degrees) to numpy arrays
latvals = lat[:]
lonvals = lon[:]

def getclosest(arr,pt):
 # print('gl 88, ', arr) #debug example, mark
 # print('gl 89, ', pt)
 # print('here')
 ix = np.argmin(np.abs(arr-pt))
 # Get 2D index for latvals and lonvals arrays from 1D index
 # return np.unravel_index(minindex_flattened, lats.shape)
 # print('getcl 93, ',ix) #debug example
 return ix

iy_min = getclosest(latvals, 301751.9)
ix_min = getclosest(lonvals, 4190721.0)

print(iy_min)
print(ix_min)

#-------------------------------------------------------------------------------
#function above generated by this online code:
# # extract lat/lon values (in degrees) to numpy arrays
# latvals = lat[:]; lonvals = lon[:]
#
# # a function to find the index of the point closest pt
# # (in squared distance) to give lat/lon value.
# def getclosest_ij(lats,lons,latpt,lonpt):
#  # find squared distance of every point on grid
#  dist_sq = (lats-latpt)**2 + (lons-lonpt)**2
#  # 1D index of minimum dist_sq element
#  minindex_flattened = dist_sq.argmin()
#  # Get 2D index for latvals and lonvals arrays from 1D index
#  return np.unravel_index(minindex_flattened, lats.shape)
#
# iy_min, ix_min = getclosest_ij(latvals, lonvals, 50., -140)
# print(iy_min)
# print(ix_min)
#-------------------------------------------------------------------------------


## 2. write location index to files
#https://www.guru99.com/reading-and-writing-files-in-python.html
# f=open("foobar.txt","a+") #appends and generates if not there
f=open("pixel_x_and_y.txt","w+") #writes file
# foo = "%d %d\n" % (ix_min, iy_min)
# print(foo)
#
# f.write("%d %d\n" % (ix_min, iy_min)
#
# f.close()






## snippit from wr
# arr = ds['Band1'][:,:]
# plt.imshow(arr)
# plt.show()
# plt.savefig('foo')
# np.where((ds['y'][:,:] == 4190721.0 and ds['x'][:,:] ==301751.9))



### direction from subnaught ###
## 1. Read the file header and parse ncols,nrows,dx,dy
## 2. for i in ncols:
##      xlist.append(i*dx+xllcorner)
##       Repeat for y

## 3.xlist - myxcoordinate, repeat for y
## 4. find smallest, grab index. np.min(np.abs())
## 5. grab yo data. Do sum shit

####### netcdf ###########
## ds = Dataset("netcdf.nc")






coords = {'x': 301751.9,'y': 4190721.0}
coords = {'x':[301751.9,301167.1,300627.2],'y': [4190721.0,4193054.6,4186970.9]}

# for k,v in coords.items():
#     coords['x']
#     print(k,v)
#
for idx in range(len(coords['x'])):
    x = coords['x'][idx] #loops through x's
    y = coords['y'][idx] #loops through y's


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#step 1 trail before switching to netCDF (5/1/19)
# for filepath in sorted(glob.glob(os.path.join(path, '*.tif'))):
#     print(filepath)
#     with open(filepath, 'r') as f:
#         lines = f.readlines()
#         lines[0:6]
#         # content = filepath.read()
#         # fp = open(filepath),'r'
#         # lines = fp.readlines()
#         # lines[0:6]
#
# sys.exit()
#
# for files in os.walk(path):
#     # for f in files:
#         # fp = open(os.path.join(path,f),'r')
#         #fp = open(os.path.join(path,files),'r')
#         # if f.split(".")[-1]=="tif":
#         #     fp = open(os.path.join(path,f.split(".")[-1]=="tif"),'r')
#             # fp = open(os.path.join(path,f),'r')
#             # print(fp)
#             # date_parse = f.split("_SUPER")[0]
